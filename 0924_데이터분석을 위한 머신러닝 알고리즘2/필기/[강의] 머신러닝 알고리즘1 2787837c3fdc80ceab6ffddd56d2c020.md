# [ê°•ì˜] ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜1

lectures clone: No
ë‚ ì§œ: 2025ë…„ 9ì›” 24ì¼
ì‹¤ìŠµ(ê³¼ì œ): No
ì¶œì„: No

**ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ í™œìš© : ë°ì´í„°ë¶„ì„ì„ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜1**

![image.png](image.png)

![image.png](image%201.png)

# ğŸŸ¦ ì„ í˜•ë³€í™˜ ë° í–‰ë ¬ ì—°ì‚°

**ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë°ì´í„°ë¶„ì„ì—ì„œ í–‰ë ¬ì˜ ì¤‘ìš”ì„±**

- ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í‘œí˜„
- ë°ì´í„°: ëŒ€ë¶€ë¶„ í–‰ë ¬í˜•íƒœë¡œ ì €ì¥
- ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜: ì„ í˜•íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€, ì‹ ê²½ë§ ë“±ì—ì„œ ê°€ì¤‘ì¹˜ì™€ ë°ì´í„° ì²˜ë¦¬ ì—°ì‚° ë° ë°ì´í„° ë³€í˜•, ì°¨ì›ì¶•ì†Œë¥¼ ìœ„í•´ í–‰ë ¬ ì‚¬ìš©
- ìµœì í™” ë° í•™ìŠµ ê³¼ì •: ê²½ì‚¬í•˜ê°•ë²• ë“± ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë° ë”¥ëŸ¬ë‹ì—ì„œ ë¯¸ë¶„ê³¼ í–‰ë ¬ ì—°ì‚° ì‚¬ìš©

## ğŸ”¹ í–‰ë ¬

![image.png](image%202.png)

![image.png](image%203.png)

### í–‰ë ¬ë§ì…ˆ, ìŠ¤ì¹¼ë¼

![image.png](image%204.png)

```python
import numpy as np

A = np.array([[1, 2], [3, 4]])  # 2x2 í–‰ë ¬
B = np.array([[5, 6], [7, 8]])  # 2x2 í–‰ë ¬

C = A + B  # í–‰ë ¬ ë§ì…ˆ
D = 2 * A  # ìŠ¤ì¹¼ë¼ ê³±

print(C)
print("=" * 50)
print(D)

>>
[[ 6  8]
 [10 12]]
==================================================
[[2 4]
 [6 8]]
```

### í–‰ë ¬ê³± dot

![image.png](image%205.png)

![image.png](image%206.png)

```python
import numpy as np

A = np.array([[1, 2, 3], [4, 5, 6]])
B = np.array([[7, 8], [9, 10], [11, 12]])

C = np.**dot**(A, B)  # í–‰ë ¬ ê³±
print(C)

>>[[ 58  64]
 [139 154]]
```

### ì „ì¹˜í–‰ë ¬ transpose

![image.png](image%207.png)

```python
import numpy as np

# ì›ë˜ í–‰ë ¬ A (2x3)
A = np.array([[1, 2, 3],
              [4, 5, 6]])

# ì „ì¹˜ í–‰ë ¬ A^T (3x2)
A_T = A.**transpose**()

print("ì›ë˜ í–‰ë ¬ A:")
print(A)
print("\nì „ì¹˜ í–‰ë ¬ A^T:")
print(A_T)

>>
ì›ë˜ í–‰ë ¬ A:
[[1 2 3]
 [4 5 6]]

ì „ì¹˜ í–‰ë ¬ A^T:
[[1 4]
 [2 5]
 [3 6]]
```

## ğŸ”¹ ì„ í˜•ë³€í™˜

ê³µê°„ì„ ë³€í˜•ì‹œí‚¤ëŠ” ê·œì¹™

![image.png](image%208.png)

![ì—†ëŠ”ê²Œì—†ëŠ”ìŠ¤ìº ì¡°](image%209.png)

ì—†ëŠ”ê²Œì—†ëŠ”ìŠ¤ìº ì¡°

![image.png](image%2010.png)

### í¬ê¸°ë³€í˜• Scaling

![image.png](image%2011.png)

## âœ… ì„ í˜•ë³€í™˜ - ì›ì ì„ ê³ ì •í•˜ì!

![image.png](image%2012.png)

3ì”© ë”í•˜ëŠ”ê±´ ë³€í™˜ì´ ì•„ë‹ˆë¼ ê·¸ëƒ¥ ìˆœìˆ˜ ì´ë™ì„

ëª¨ë“  ë²¡í„°ì— ì¼ì • ê°’ì„ ë”í•˜ëŠ” ì´ë™ì˜ ê°œë…

ì„ í˜•ë³€í™˜ì€ ì›ì ì´ë¼ëŠ”ê±¸ ë³´ì „í•´ì•¼í•˜ê¸°ë•Œë¬¸ì— ì´ë™ì„ í•˜ëŠ” ìˆœê°„ ì›ì ì´ ë³€í•¨ â†’ ì„ í˜•ë³€í™˜ì´ ì•„ë‹˜. 

# ğŸŸ¦ Regression (íšŒê·€)

https://recipesds.tistory.com/entry/%EB%8F%84%EB%8C%80%EC%B2%B4-%EC%99%9C-%ED%9A%8C%EA%B7%80%EB%8A%94-%ED%9A%8C%EA%B8%B0%EB%9D%BC%EA%B3%A0-%EB%B6%88%EB%A6%AC%EB%8A%94-%EA%B1%B8%EA%B9%8C

ê·¸ë‹ˆê¹Œ íšŒê·€regressionì€ ì•„ë²„ì§€ë‘ ì•„ë“¤ì˜ í‚¤ì˜ ìƒê´€ê´€ê³„ë¥¼ ì—°êµ¬í•  ë•Œ â€˜ì•„ ë‚¨ìë“¤ì˜ í‚¤ëŠ” í‰ê· ìœ¼ë¡œ ëŒì•„ê°€ëŠ”-íšŒê·€í•˜ëŠ”-ì„±ì§ˆì´ ìˆêµ¬ë‚˜â€¦ í•˜ê³  ì•„ë¹ í‚¤â†’ì•„ë“¤í‚¤ ì´ëŸ° ë…ë¦½â†’ì¢…ì† ê´€ê³„ë¥¼ ì—°êµ¬í–ˆëŠ”ë°, ì´ê²Œ ì‚¬ì‹¤ì€ í‹€ë ¸ì§€ë§Œ ì´ ì‹¤ë§ˆë¦¬ â€˜íšŒê·€â€™ë¼ëŠ”ê²Œ ë‚¨ì•„ì„œ ê± ì´ë¦„ì´ íšŒê·€ì¸ê±°ì„. 

ì´ì œ í™”ì¥ì‹¤ì—ì„œ í™”ì¥ì•ˆí•˜ì§€ë§Œ ì˜›ë‚ ì—ëŠ” ì •ë§ í™”ì¥ì‹¤ì—ì„œ í™”ì¥í–ˆì–´ì„œ ì´ë¦„ì´ í™”ì¥ì‹¤ì¸ê²ƒì²˜ëŸ¼ í•˜í•˜í•˜ ğŸª 

![image.png](image%2013.png)

ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•œë‹¤ 

*íšŒê·€ë¶„ì„ì„ ì¢€ë” ì •í™•í•˜ê²Œ ì–˜ê¸°í•˜ë©´ ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•¨ìœ¼ë¡œì¨ ì–´ë–¤ íŠ¹ì •í•œ ë³€ìˆ˜ì˜ ê°’ì„ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ë¡œ ì„¤ëª…í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” í†µê³„ì  ê¸°ë²•*

ë…ë¦½ë³€ìˆ˜ â†’ ì¢…ì†ë³€ìˆ˜ 

![image.png](image%2014.png)

![image.png](image%2015.png)

![image.png](image%2016.png)

![image.png](image%2017.png)

![image.png](image%2018.png)

## ì„ í˜•íšŒê·€

ì…ë ¥ë³€ìˆ˜ì™€ ì¶œë ¥ë³€ìˆ˜ê°„ì˜ ì„ í˜•ê´€ê³„ë¥¼ ê°€ì •í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸

ë°ì´í„°ê°€ ì§ì„ ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆì„ ë•Œ, ê°€ì¥ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ë°©ë²•

![image.png](image%2019.png)

![ë‹¤ì¤‘ì˜ í”¼ì²˜ê°€ ìˆë‹¤ - ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆë‹¤ - ì‹ ë¢°ë„ê°€ ë‚®ì•„ì§€ê³  ì˜ˆì¸¡ì´ ì•ˆë¨](image%2020.png)

ë‹¤ì¤‘ì˜ í”¼ì²˜ê°€ ìˆë‹¤ - ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆë‹¤ - ì‹ ë¢°ë„ê°€ ë‚®ì•„ì§€ê³  ì˜ˆì¸¡ì´ ì•ˆë¨

ì˜ˆì‹œ: ìˆ˜ì¹˜ì ì¸ê²ƒ, í¬ê¸°-ê°€ê²©, ë¹„ìš©-íŒë§¤ëŸ‰ 

íŒŒë€ì : ğŸ’™ ì„ í˜•íšŒê·€ì—ì„œ ì˜ˆì¸¡í•œ ì„ . ë°ì´í„°ì˜ ì „ë°˜ì ì¸ê±¸ ëª¨ë¸ë§í•œ ì§ì„ .

ë³´ë¼ì : ğŸ’œ ì‹¤ì œ ê°œë³„ ë°ì´í„° í¬ì¸íŠ¸ 

ì´ì œ ì´ ë‘˜ ì‚¬ì´ì˜ ì˜¤ì°¨ë“¤ì„ ê³„ì‚°í•´ì„œ ëª¨ë¸ì˜ ì í•©ì„±ì„ ê³„ì‚°í•¨ (ì´ë•Œ ì´ ì˜¤ì°¨ë“¤ì„ ê³„ì‚°í•˜ëŠ” ì‹ë“¤ì´ ë‹¤ì–‘í•˜ê²Œ ì¡´ì¬í•¨ - ì œê³±ì„ í•˜ë˜(ë§ˆì´ë„ˆìŠ¤ê°’ë„ ìˆìœ¼ë‹ˆê¹Œ), í‰ê· ì„ ë‚´ë˜â€¦.. ë“±ë“±ë“±)

scikit-learn ì˜ˆ

```python
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing
import pandas as pd

# ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ ë¡œë“œ
data = fetch_california_housing()
X = pd.DataFrame(data.data, columns=data.feature_names)  # ë…ë¦½ ë³€ìˆ˜(íŠ¹ì§• ë°ì´í„°)
y = data.target  # ì¢…ì† ë³€ìˆ˜ (ì¤‘ê°„ ì£¼íƒ ê°€ê²©)

# ì£¼íƒ í¬ê¸°(House Size) íŠ¹ì„±ë§Œ ì„ íƒ
X_house_size = X[['HouseAge']]

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = 
(
    X_house_size, y, test_size=0.3, random_state=42 #ê´€ìš©ì ìœ¼ë¡œ 42ë¼ëŠ” ìˆ«ìë¥¼ ë§ˆë‹ˆ ì”€
)

# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
**y_pred = model.predict(X_test)**

# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)  # í‰ê·  ì œê³± ì˜¤ì°¨ ê³„ì‚°
r2 = r2_score(y_test, y_pred)  # ê²°ì • ê³„ìˆ˜(RÂ²) ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.4f}")

>>
Mean Squared Error (MSE): 1.30
RÂ² Score: 0.0107
```

## ë‹¤ì¤‘íšŒê·€

ì—¬ëŸ¬ê°œì˜ í”¼ì²˜ë¥¼ ì‚¬ìš©í•˜ëŠ” íšŒê·€

![image.png](image%2021.png)

ê° ì…ë ¥ë³€ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ì¤€ ë‹¤ìŒì— ê·¸ ê°’ì„ ëª¨ë‘ ë”í•˜ì—¬ ì˜ˆì¸¡ ê°’ì„ ê³„ì‚°í•œë‹¤. 

![image.png](image%2022.png)

Xì—ì„œ íŠ¹ì • ì»¬ëŸ¼ì„ ë½‘ëŠ”ê²Œ ì•„ë‹ˆë¼ Xì „ì²´ë¥¼ ì‚¬ìš©í•œë‹¤ (ë‹¤ì¤‘ì„ í˜•íšŒê·€)

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing
import pandas as pd
import matplotlib.pyplot as plt

# ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ ë¡œë“œ
data = fetch_california_housing()
**X** = pd.DataFrame(data.data, columns=data.feature_names)  # íŠ¹ì„± ë°ì´í„°
y = data.target  # ëª©í‘œ ë³€ìˆ˜ (ì¤‘ê°„ ì£¼íƒ ê°€ê²©)

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
**X_train**, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ëª¨ë¸ í‰ê°€
mse = **mean_squared_error**(y_test, y_pred)  # í‰ê·  ì œê³± ì˜¤ì°¨ ê³„ì‚°
	#ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ì‚¬ì´ì˜ ê°’ì„ ê³„ì‚°í•œë‹¤. 
r2 = r2_score(y_test, y_pred)  # ê²°ì • ê³„ìˆ˜(RÂ²) ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.4f}")

>>
Mean Squared Error (MSE): 0.53
RÂ² Score: 0.5958
```

> (ë‹¨ì¼ì„ í˜•íšŒê·€)
> 
> 
> Mean Squared Error (MSE): 1.30
> RÂ² Score: 0.0107
> ì•„ê¹Œë³´ë‹¤ í›¨ì”¬ ë†’ì•„ì§„ R^2ìŠ¤ì½”ì–´ â†’ í›¨ì”¬ ì˜ˆì¸¡ì„ ì˜í•œë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆìŒ
> 

## ë‹¤í•­íšŒê·€

ì…ë ¥ë³€ìˆ˜ì™€ ì¶œë ¥ë³€ìˆ˜ê°„ì˜ **ë¹„ì„ í˜•ê´€ê³„**ë¥¼ ëª¨ë¸ë§í•˜ëŠ” íšŒê·€ë°©ë²•

![image.png](image%2023.png)

![image.png](image%2024.png)

![image.png](image%2025.png)

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ ë¡œë“œ
data = fetch_california_housing()
df = pd.DataFrame(data.data, columns=data.feature_names)  # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
df["MedHouseVal"] = data.target  # ëª©í‘œ ë³€ìˆ˜(ì£¼íƒ ê°€ê²©) ì¶”ê°€

# íŠ¹ì • íŠ¹ì„± ì„ íƒ (ê°€êµ¬ë‹¹ í‰ê·  ë°© ê°œìˆ˜)
X = df[["AveRooms"]]  # ë…ë¦½ ë³€ìˆ˜(íŠ¹ì§•)
y = df["MedHouseVal"]  # ì¢…ì† ë³€ìˆ˜(ì£¼íƒ ê°€ê²©)

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#============================ìœ„ì˜ ì¼ë°˜ì ì¸ íšŒê·€ì™€ ë™ì¼============================

**# ë‹¤í•­ íŠ¹ì„± ë³€í™˜ (ì°¨ìˆ˜=2)
poly = PolynomialFeatures(degree=2)  # Xë¥¼ [1, X, X^2] í˜•íƒœë¡œ ë³€í™˜ #2ì°¨ì‹ê¹Œì§€ 
X_train_poly = poly.fit_transform(X_train)
	# fit_transform: ë°ì´í„°ì˜ íŠ¹ì„±ì— ë§ì¶˜ë‹¤ 
	# í•™ìŠµtrainì„ ìœ„í•œ ê³¼ì •ì—ì„œ ë°ì´í„°ì— ëŒ€í•´ ë³€í˜•ì´ ìƒê¸°ë‹ˆê¹Œ 
	# -íŠ¹ì„±ì— ë§ì¶°ì„œ fití•˜ê²Œ transformì‹œí‚¨ë‹¤)
X_test_poly = poly.transform(X_test)
	#í›ˆë ¨ìš©ë°ì´í„°ëŠ” fití•  í•„ìš”ê°€ ì—†ë‹¹**

# ë‹¤í•­ íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_train_poly, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test_poly)

# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)  # í‰ê·  ì œê³± ì˜¤ì°¨ ê³„ì‚°
r2 = r2_score(y_test, y_pred)  # ê²°ì • ê³„ìˆ˜(RÂ²) ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.4f}")

>>
Mean Squared Error (MSE): 1.25
RÂ² Score: 0.0502
```

# ğŸŸ¦ ë² ì´ì¦ˆ ì •ë¦¬, ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ â“

ìŠ¤íŒ¸ê³¼ ì •ìƒë©”ì¼ì€ **ë…ë¦½ì‚¬ê±´**ì„ (ë³„ê°œì˜ ë¬¸ì œ, ìŠ¤íŒ¸ì´ 5ê°œì™“ë‹¤ê³ í•´ì„œ ë‹¤ìŒì— ìŠ¤íŒ¸ì´ ì˜¬ í™•ë¥ ? ì´ëŸ°ê±° ê³„ì‚° ëª»í•¨ í•˜í•˜í•˜)

ì´ëŸ°ê±°ë¥¼ ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•  ìˆ˜ ìˆìŒ

![image.png](image%2026.png)

![image.png](image%2027.png)

Bê°€ ë°œìƒí–ˆì„ ë•Œ Aê°€ ë°œìƒí•  í™•ë¥ 

ë©”ì¼ì´ ìŠ¤íŒ¸ì¼ í™•ë¥ ì„ ê³„ì‚°í•´ë³´ì~

b: ë©”ì¼ì— â€˜í• ì¸â€™ì´ë¼ëŠ” í‚¤ì›Œë“œê°€ ë“¤ì–´ê°€ìˆì„ í™•ë¥ 

a: ìŠ¤íŒ¸ì¼ í™•ë¥ 

p(a|b) í• ì¸ì´ ë“¤ì–´ìˆì„ ë•Œ ìŠ¤íŒ¸ì¼ í™•ë¥ 

![image.png](image%2028.png)

![image.png](image%2029.png)

![image.png](image%2030.png)

```python
# ì „ì²´ ì´ë©”ì¼ ì¤‘ 40%ê°€ ìŠ¤íŒ¸
# ì „ì²´ ì´ë©”ì¼ ì¤‘ 60%ê°€ ì •ìƒ ë©”ì¼ 
# ì‚¬ì „ í™•ë¥  (Prior)
P_spam = 0.4  # ìŠ¤íŒ¸ ë©”ì¼ í™•ë¥ 
P_ham = 0.6   # ì •ìƒ ë©”ì¼ í™•ë¥ 

# ë‹¨ì–´ë³„ ì¡°ê±´ë¶€ í™•ë¥  (ê° ë‹¨ì–´ê°€ íŠ¹ì •í•œ ë©”ì¼ì— í¬í•¨ë  í™•ë¥ )
# ì˜ˆì œ ë‹¨ì–´ (ìŠ¤íŒ¸ ë‹¨ì–´: "ë‹¹ì²¨", "ë¬´ë£Œ", "í˜œíƒ", ì •ìƒ ë‹¨ì–´: "íšŒì˜", "ë³´ê³ ì„œ", "í˜‘ì¡°")
# ex) ë‹¹ì²¨ì´ ìŠ¤íŒ¸ ë©”ì¼ì—ì„œ ë“±ì¥í•  í™•ë¥ ì´ 12/30
P_ë‹¹ì²¨_given_spam = 12 / 30
P_ë¬´ë£Œ_given_spam = 10 / 30
P_í˜œíƒ_given_spam = 8 / 30

P_ë‹¹ì²¨_given_ham = 2 / 20
P_ë¬´ë£Œ_given_ham = 3 / 20
P_í˜œíƒ_given_ham = 1 / 20

**# íŠ¹ì • ì´ë©”ì¼ì´ "ë‹¹ì²¨", "ë¬´ë£Œ", "í˜œíƒ"ì„ í¬í•¨í•  ê²½ìš° í™•ë¥  ê³„ì‚°**
P_words_given_spam = P_ë‹¹ì²¨_given_spam * P_ë¬´ë£Œ_given_spam * P_í˜œíƒ_given_spam
P_words_given_ham = P_ë‹¹ì²¨_given_ham * P_ë¬´ë£Œ_given_ham * P_í˜œíƒ_given_ham

# ìµœì¢… í™•ë¥  ê³„ì‚° (Posterior)
P_spam_given_words = P_words_given_spam * P_spam
P_ham_given_words = P_words_given_ham * P_ham

# ê²°ê³¼ ì¶œë ¥
{
    "P(ìŠ¤íŒ¸ | ë‹¹ì²¨, ë¬´ë£Œ, í˜œíƒ)": P_spam_given_words,
    "P(ì •ìƒ | ë‹¹ì²¨, ë¬´ë£Œ, í˜œíƒ)": P_ham_given_words,
    "ê²°ë¡ ": "ì •ìƒ ë©”ì¼" if P_ham_given_words > P_spam_given_words else "ìŠ¤íŒ¸ ë©”ì¼"
}

>>
{'P(ìŠ¤íŒ¸ | ë‹¹ì²¨, ë¬´ë£Œ, í˜œíƒ)': 0.014222222222222223,
 'P(ì •ìƒ | ë‹¹ì²¨, ë¬´ë£Œ, í˜œíƒ)': 0.00045,
 'ê²°ë¡ ': 'ìŠ¤íŒ¸ ë©”ì¼'}
```

# ğŸŸ¦ Classificationë¥˜

ğŸ” ğŸ“§

ì…ë ¥ë°ì´í„°ê°€ ì—¬ëŸ¬ ê°œì˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ì— ì†í•˜ë„ë¡ ì§€ì •í•˜ëŠ” ì‘ì—…

ì£¼ë¡œ ì§€ë„í•™ìŠµë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë©°, ë°ì´í„°ì˜ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ ë°ì´í„°ê°€ ì–´ëŠ ë²”ì£¼ì— ì†í•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•˜ì. 

![image.png](image%2031.png)

í•™ìŠµì•Œê³ ë¦¬ì¦˜ì€ í•¨ìˆ˜ fë¥¼ ìƒì„±í•˜ì—¬ ì…ë ¥ë²¡í„° xê°€ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ yì— ì†í•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•œë‹¤

ì˜ˆ: ì´ë¯¸ì§€ë¶„ë¥˜

![image.png](image%2032.png)

![image.png](image%2033.png)

ë¶„ë¥˜: ë²”ì£¼ (ì´ì‚°ì ì¸ ê°’) 

íšŒê·€: ì˜ˆì¸¡ (ì—°ì†ì ì¸ ì‹¤ìˆ˜) 

![image.png](image%2034.png)

![image.png](image%2035.png)

![image.png](image%2036.png)

## ë¶„ë¥˜ ë¬¸ì œì— íšŒê·€ì•Œê³ ë¦¬ì¦˜ ì ìš©í•˜ê¸°

![image.png](image%2037.png)

ğŸ›« ì–´ë–¤ ë¹„í–‰ê¸°ê°€ ëœ° ë•Œ ì§€ì—°ì—¬ë¶€ë¥¼ í™•ì¸í•  ë•Œ í’ì†ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤. 

íŠ¹ì • ê²½ê³„ ì´ìƒì´ ë˜ë©´ ì§€ì—°ì„ ì‹œí‚¨ë‹¤ ~ ë¥¼ ë°”ì´ë„ˆë¦¬ í˜•íƒœë¡œ êµ¬ë¶„í•˜ê³  ì‹¶ë‹¤. 

## ë¡œì§€ìŠ¤í‹± íšŒê·€

![image.png](image%2038.png)

![image.png](image%2039.png)

íšŒê·€ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ë¶„ë¥˜ëª¨ë¸

0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë³€í™˜í•´ì„œ ì´ ê°’ìœ¼ë¡œ ë¶„ë¥˜ë¥¼ í•˜ê² ë‹¤ - í•´ì„ì´ ê°„ë‹¨í•˜ê³  ê³„ì‚°ì´ ë¹ ë¥´ë‹¤

but ë¹„ì„ í˜• ë°ì´í„°ì—ëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. ì„ í˜•ì ì¼ ë•Œ íš¨ê³¼ì ! ë³µì¡í•œ ê²°ì •ê²½ê³„ë¥¼ ë§Œë“¤ê¸°ëŠ” ì–´ë µë‹¤. 

![image.png](image%2040.png)

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# ë°ì´í„°ì…‹ ë¡œë“œ (Iris ë°ì´í„°ì…‹ ì‚¬ìš©)
data = load_iris()
X = data.data  # íŠ¹ì„± ë°ì´í„°
y = data.target  # ëª©í‘œ ë³€ìˆ˜ (í´ë˜ìŠ¤ ë ˆì´ë¸”)

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ëª¨ë¸ í‰ê°€
accuracy = accuracy_score(y_test, y_pred)  # ì •í™•ë„ ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Accuracy: {accuracy * 100:.2f}%")
```

## ê²°ì •íŠ¸ë¦¬ ğŸŒ³

**ì¡°ê±´**ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ **ë¶„ê¸°**í•´ì„œ **ìµœì¢…ë¦¬í”„ë…¸ë“œì—ì„œ ì˜ˆì¸¡ê²°ê³¼**ë¥¼ ë‚˜íƒ€ë‚´ê²Œ í•¨ 

![image.png](image%2041.png)

![image.png](image%2042.png)

- ì—”íŠ¸ë¡œí”¼
- ì§€ë‹ˆì§€ìˆ˜

5ëŒ€5ë¡œ ë¶„ë¦¬ë˜ì–´ìˆëŠ” ë¶ˆí™•ì‹¤í•œ ìƒíƒœë‹¤

trueë§Œ 1ê°œê³  falseë§Œ 0ê°œë‹¤ - ì—”íŠ¸ë¡œí”¼ê°€ ë‚®ë‹¤ - ìˆœìˆ˜í•˜ë‹¤ - ìˆœë„ê°€ ë†’ë‹¤ ë¼ê³  íŒë‹¨ ê°€ëŠ¥

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# ë°ì´í„°ì…‹ ë¡œë“œ (Iris ë°ì´í„°ì…‹ ì‚¬ìš©)
data = load_iris()
X = data.data  # íŠ¹ì„± ë°ì´í„°
y = data.target  # ëª©í‘œ ë³€ìˆ˜ (í´ë˜ìŠ¤ ë ˆì´ë¸”)

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ê²°ì •íŠ¸ë¦¬ ëª¨ë¸ í•™ìŠµ
model = **DecisionTreeClassifier**(random_state=42)  # ê²°ì •íŠ¸ë¦¬ ëª¨ë¸ ìƒì„±
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ëª¨ë¸ í‰ê°€
accuracy = accuracy_score(y_test, y_pred)  # ì •í™•ë„ ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Accuracy: {accuracy * 100:.2f}%")

```

![image.png](image%2043.png)

# ğŸŸ¦ KNN

![image.png](image%2044.png)

![image.png](image%2045.png)

![image.png](image%2046.png)

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris

# ë°ì´í„°ì…‹ ë¡œë“œ (Iris ë°ì´í„°ì…‹ ì‚¬ìš©)
data = load_iris()
X = data.data  # íŠ¹ì„± ë°ì´í„°
y = data.target  # ëª©í‘œ ë³€ìˆ˜ (í´ë˜ìŠ¤ ë ˆì´ë¸”)

# ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# KNN ëª¨ë¸ í•™ìŠµ (K=5ë¡œ ì„¤ì •)
model = KNeighborsClassifier(**n_neighbors=5**)
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ëª¨ë¸ í‰ê°€
accuracy = accuracy_score(y_test, y_pred)  # ì •í™•ë„ ê³„ì‚°

# ê²°ê³¼ ì¶œë ¥
print(f"Accuracy: {accuracy * 100:.2f}%")
```