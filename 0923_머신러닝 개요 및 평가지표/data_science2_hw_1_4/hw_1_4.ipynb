{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea11fec",
   "metadata": {},
   "source": [
    " <학습목표>\n",
    " \n",
    " - 모델의 예측 결과를 분석하기 위해 혼동 행렬(confusion matrix)을 생성하는 방법을 학습한다. \n",
    " - 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-score 등의 평가 지표를 계산하는 능력을 기른다. \n",
    " - 각 클래스별 성능을 개별적으로 평가하고 해석하는 방법을 익힌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f099ba",
   "metadata": {},
   "source": [
    "<학습 개념>\n",
    "- confusion_matrix(): 모델이 예측한 값과 실제값을 비교하여 혼동 행렬을 생성하는 함수 \n",
    "- accuracy_score(): 모델이 올바르게 예측한 비율을 계산하는 함수 \n",
    "- precision_score(), recall_score(), f1_score(): 개별 클래스에 대한 정밀도, 재현율, F1-score를 계산하는 함수 \n",
    "- classification_report(): 모델의 전체 성능을 요약하여 출력하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1ff60",
   "metadata": {},
   "source": [
    "<실험 절차>\n",
    "\n",
    "1. confusion_matrix()를 사용하여 혼동 행렬을 생성한다. \n",
    "2. accuracy_score()를 사용하여 모델의 전체 정확도를 계산한다. \n",
    "3. precision_score(), recall_score(), f1_score()를 사용하여 각 클래스(0과 1)에 대한 개별 성능 지표를 계산한다. \n",
    "4. classification_report()를 사용하여 모델의 전체 평가 결과를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17dc25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "#sklearn에서 함수들을 가져옴\n",
    "# confusion_matrix, \n",
    "# classification_report, \n",
    "# accuracy_score, \n",
    "# precision_score, \n",
    "# recall_score, \n",
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d08326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 실제값(y_true)과 예측값(y_pred) 생성\n",
    "# 교통사고 예측 모델이 예측한 값과 실제 사고 여부 데이터를 비교하여 평가합니다.\n",
    "# 0: 사고 없음, 1: 사고 발생을 나타내는 이진 분류 문제\n",
    "y_true = [0, 1, 1, 0, 1, 0, 1, 1, 0, 0]  # 실제 값 (Ground Truth, 참값)\n",
    "y_pred = [0, 1, 0, 0, 1, 0, 1, 1, 1, 0]  # 모델이 예측한 값 (Predicted Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74607b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동 행렬 (Confusion Matrix):\n",
      "[[4 1]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "# 2. 혼동 행렬(confusion matrix) 생성\n",
    "# 혼동 행렬은 모델이 얼마나 정확하게 예측했는지를 나타내는 중요한 지표입니다.\n",
    "cm = confusion_matrix(y_true, y_pred) #confusion_matrix에 y_rue랑 y_pred값을 넣어준다\n",
    "print(\"혼동 행렬 (Confusion Matrix):\")\n",
    "print(cm)  # 혼동 행렬 출력\n",
    "\n",
    "# [TF, FP]\n",
    "# [FN, TP] 순으로 찍힌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2430f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 정확도 (Accuracy): 0.80\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델의 정확도(Accuracy) 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n모델 정확도 (Accuracy): {:.2f}\".format(accuracy))  # 정확도 출력\n",
    "\n",
    "#맞춘거/전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9d5c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "개별 클래스별 Precision, Recall, F1-score:\n",
      "Class 0 - Precision: 0.80, Recall: 0.80, F1-score: 0.80\n",
      "Class 1 - Precision: 0.80, Recall: 0.80, F1-score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# 4. 개별 클래스(0: 사고 없음, 1: 사고 발생)에 대한 Precision, Recall, F1-score 계산\n",
    "# 각 클래스(0 또는 1)에 대해 정밀도, 재현율, F1-score를 개별적으로 계산합니다.\n",
    "\n",
    "# Precision (정밀도): 모델이 '사고 발생'이라고 \"예측\"한 값 중에서 실제로 사고가 발생한 비율\n",
    "precision_class_0 = precision_score(y_true, y_pred, pos_label=0) \n",
    "precision_class_1 = precision_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "# Recall (재현율): \"실제\" 사고 발생 중에서 모델이 '사고 발생'으로 올바르게 예측한 비율\n",
    "recall_class_0 = recall_score(y_true, y_pred, pos_label=0)\n",
    "recall_class_1 = recall_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "# F1-score: Precision과 Recall의 조화 평균 (균형을 고려한 성능 평가 지표)\n",
    "f1_class_0 = f1_score(y_true, y_pred, pos_label=0)\n",
    "f1_class_1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "print(\"\\n개별 클래스별 Precision, Recall, F1-score:\")\n",
    "print(\"Class 0 - Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}\".format(precision_class_0, recall_class_0, f1_class_0))  \n",
    "print(\"Class 1 - Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}\".format(precision_class_1, recall_class_1, f1_class_1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d2496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 모델 성능 평가:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.80      0.80      0.80        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 전체 Classification Report 출력\n",
    "print(\"\\n전체 모델 성능 평가:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
